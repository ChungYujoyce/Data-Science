as america comes to grips with two more violent homegrown plots an attempt to mail pipe bombs to prominent democrats and a mass shooting at a pittsburgh synagogue reality and surreality may seem hard to disentangle experts are working to figure out exactly what happened in each case and why on levels ranging from the societal to forensic but it appears that the two suspects shared at least one habit engaging with extreme content online robert bowers the suspect in the pittsburgh shooting posted a message on a niche social network known to be used by white supremacists shortly before opening fire at the tree of life synagogue cesar sayoc the florida man charged with sending explosive material to political figures left a trail of conspiracy theories and right wing sensationalism on facebook while their use of technology may help reveal their motives it also speaks to bigger problems that researchers are racing to better understand chief among them is the way that the internet can make irrational viewpoints seem commonplace a lot of our behavior is driven by what we think other people do and what other people find acceptable says nour kteily an associate professor at northwestern s kellogg school of management who studies dehumanization and hostility and there s a good chance that even those who avoid the dark corners of the web are encountering extreme ideas about what is right and who is wrong a facebook spokesperson says the company took action on 2 5 million pieces of content classified as hate speech in the first quarter of 2018 there have always been people who espouse vitriol but the emergence of these online platforms has reshaped the conversation kteily says they in many ways amplify the danger of things like dehumanizing speech or hate speech marginal ideas can now spread faster and further creating an impression that they are less marginal and more mainstream big technology companies are acknowledging the dangers researchers have already uncovered when it comes to the ways that encountering hateful speech can skew attitudes in one 2015 study people who were exposed to homophobic epithets tended to rate gay people as less human and physically distance themselves from a gay man in subsequent tasks and researchers have long warned that dehumanizing people is a tactic that goes hand in hand with oppressing them because it helps create mental distance between groups we are permitted to treat non human animals in ways that are impermissible in the treatment of human beings david livingstone smith a professor of philosophy at the university of new england explained in a previous interview with time such language can help disable inhibitions against acts of harm he said one question raised by the pittsburgh shooting is what happens when extremists are shut out of mainstream social networks as companies like facebook and twitter take a harder line on these issues facebook has been hiring content moderators and subject matter experts at a rapid clip hoping to do a better job of proactively finding hate speech and identifying extremist organizations twitter continues to develop a more stringent policy on what constitutes dehumanizing speech that violates its terms language that makes someone less than human can have repercussions off the service including normalizing serious violence twitter employees wrote in a post announcing proposed policy language gab a social media site on which bowers wrote anti semitic posts disavowed all acts of violence and terrorism in statements to time and other publications in the aftermath of the shooting but the site has become a haven for white supremacists and other extremists given its promise of letting people espouse ideas that might get them banned elsewhere says joan donovan an expert in media manipulation at research institute data society what that does is create a user population on gab of people who are highly tolerant of those views she says that in turn might make things like rantings about jewish conspiracies seem more widespread than they would on a platform where poisonous posts are surrounded and perhaps diluted by billions of rational ones bowers final post before the shooting read in part screw your optics i m going in the term optics donovan says likely refers to tactics discussed among white supremacists specifically the idea that the movement will be more successful if its members are perceived as non violent victims of anti white thought police among the figures the movement portrays as its own oppressors she says are big technology companies w e are in a war to speak freely on the internet a gab associated account wrote on medium before that company suspended it in the wake of the shooting the post accused silicon valley companies of purg ing any ideology that does not conform to their own echo chamber bubble world such sites where the alt right flocks have been described as alt tech donovan says that these niche platforms are places where many harassment campaigns are organized where lots of conspiracy talk is organized racist and sexist memes that might get an account suspended on other platforms are easy to find the problem is when you re highly tolerant of those kinds of things donovan explains other more sane and more normal people don t stay though social networks might seem well established at this point more than a decade after facebook was founded academics are lagging behind when it comes to understanding all the effects these evolving platforms might be having on users behavior and well being experts interviewed for this article were not aware of research that investigates on an individual level the possible link between posting extreme or hateful content online and the likelihood of being aggressive offline posting can serve a public commitment device kteily says but that s far from a causal link newer research is attempting at least in the aggregate to better understand the relationship between activity on social networks and violence in the offline world carlo schwarz and karsten m ller researchers associated with the university of warwick and princeton university respectively analyzed every anti refugee attack that had occurred in germany over a two year period more than 3 000 instances and looked at variables ranging from the wealth of each community to the numbers of refugees living there one factor that cropped up across the country is that attacks tended to occur in towns where there was more usage of facebook a platform where users encounter anti refugee sentiment the study s methodology has come under some criticism and schwarz emphasizes that the findings need to be replicated before universal conclusions are drawn especially because isolated internet outages across germany helped provide special circumstances for their study when access to the internet went down in localities with high amounts of facebook usage they found that attacks on refugees dropped too but what their research suggests schwarz says is that there is a sub group of people who seem to be pushed toward violent acts by the exposure to online hate speech the echo chamber effect of social networks may be part of the problem when people are exposed to the same targeted criticisms over and over he says it may change their perception about how acceptable it is to commit acts of violence against minority groups facebook twitter and google are dedicating resources to the problem yet there are many challenges as algorithms are designed to pick up certain red flag words extremist groups adopt coded language to spread the same old ideas content moderators need to understand myriad languages and cultures and the sheer volume of posts on facebook alone which number in the billions each day is overwhelming the company says that it finds 38 of hate speech before it s reported a smaller proportion than for terror propaganda and nudity the company expects that number to improve a spokesperson says also acknowledging the difficulty of tackling content that tends to be context dependent and while major tech companies may feel that getting a handle on this problem is a business imperative a twitter spokesperson says that maintaining healthy conversation is a top priority current law largely shields platforms from responsibility for the content on their platforms that means that while some social networks may get serious in tackling extremist speech there is no legal mandate for all platforms to follow suit that is one reason in the wake of these latest plots that some lawmakers are renewing calls for tighter regulation on social media in the meantime academics will keep trying to provide research that helps companies make decisions based on data rather than good intentions research is obviously slow says schwarz who is now investigating whether there is a connection between twitter usage and offline violence in the u s it s still a new field write to katy steinmetz at katy steinmetz time com 