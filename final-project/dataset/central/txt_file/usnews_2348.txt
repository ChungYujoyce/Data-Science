sitting in front of a computer not long ago a tenured history professor faced a challenge that billions of us do every day deciding whether to believe something on the internet on his screen was an article published by a group called the american college of pediatricians that discussed how to handle bullying in schools among the advice it offered schools shouldn t highlight particular groups targeted by bullying because doing so might call attention to temporarily confused adolescents scanning the site the professor took note of the org web address and a list of academic looking citations the site s sober design devoid of flashy autoplaying videos lent it credibility he thought after five minutes he had found little reason to doubt the article i m clearly looking at an official site he said what the professor never realized as he focused on the page s superficial features is that the group in question is a socially conservative splinter faction that broke in 2002 from the mainstream american academy of pediatrics over the issue of adoption by same sex couples it has been accused of promoting antigay policies and the southern poverty law center designates it as a hate group trust was the issue at hand the bookish professor had been asked to assess the article as part of an experiment run by stanford university psychologist sam wineburg his team known as the stanford history education group has given scores of subjects such tasks in hopes of answering two of the most vexing questions of the internet age why are even the smartest among us so bad at making judgments about what to trust on the web and how can we get better wineburg s team has found that americans of all ages from digitally savvy tweens to high iq academics fail to ask important questions about content they encounter on a browser adding to research on our online gullibility other studies have shown that people retweet links without clicking on them and rely too much on search engines a 2016 pew poll found that nearly a quarter of americans said they had shared a made up news story in his experiments mit cognitive scientist david rand has found that on average people are inclined to believe false news at least 20 of the time we are all driving cars but none of us have licenses wineburg says of consuming information online our inability to parse truth from fiction on the internet is of course more than an academic matter the scourge of fake news and its many cousins from clickbait to deep fakes realistic looking videos showing events that never happened have experts fearful for the future of democracy politicians and technologists have warned that meddlers are trying to manipulate elections around the globe by spreading disinformation that s what russian agents did in 2016 according to u s intelligence agencies and on july 31 facebook revealed that it had found evidence of a political influence campaign on the platform ahead of the 2018 midterm elections the authors of one now defunct page got thousands of people to express interest in attending a made up protest that apparently aimed to put white nationalists and left wingers on the same streets but the stakes are even bigger than elections our ability to vet information matters every time a mother asks google whether her child should be vaccinated and every time a kid encounters a holocaust denial on twitter in india false rumors about child kidnappings that spread on whatsapp have prompted mobs to beat innocent people to death it s the equivalent of a public health crisis says alan miller founder of the nonpartisan news literacy project there is no quick fix though tech companies are under increasing pressure to come up with solutions facebook lost more than 120 billion in stock value in a single day in july as the company dealt with a range of issues limiting its growth including criticism about how conspiracy theories spread on the platform but engineers can t teach machines to decide what is true or false in a world where humans often don t agree in a country founded on free speech debates over who adjudicates truth and lies online are contentious many welcomed the decision by major tech companies in early august to remove content from florid conspiracy theorist alex jones who has alleged that passenger jet contrails are damaging people s brains and spread claims that families of sandy hook massacre victims are actors in an elaborate hoax but others cried censorship and even if law enforcement and intelligence agencies could ferret out every bad actor with a keyboard it seems unwise to put the government in charge of scrubbing the internet of misleading statements what is clear however is that there is another responsible party the problem is not just malicious bots or chaos loving trolls or macedonian teenagers pushing phony stories for profit the problem is also us the susceptible readers and experts like wineburg believe that the better we understand the way we think in the digital world the better chance we have to be part of the solution we don t fall for false news just because we re dumb often it s a matter of letting the wrong impulses take over in an era when the average american spends 24 hours each week online when we re always juggling inboxes and feeds and alerts it s easy to feel like we don t have time to read anything but headlines we are social animals and the desire for likes can supersede a latent feeling that a story seems dicey political convictions lead us to lazy thinking but there s an even more fundamental impulse at play our innate desire for an easy answer humans like to think of themselves as rational creatures but much of the time we are guided by emotional and irrational thinking psychologists have shown this through the study of cognitive shortcuts known as heuristics it s hard to imagine getting through so much as a trip to the grocery store without these helpful time savers you don t and can t take the time and energy to examine and compare every brand of yogurt says wray herbert author of on second thought outsmarting your mind s hard wired habits so we might instead rely on what is known as the familiarity heuristic our tendency to assume that if something is familiar it must be good and safe these habits of mind surely helped our ancestors survive the problem is that relying on them too much can also lead people astray particularly in an online environment in one of his experiments mit s rand illustrated the dark side of the fluency heuristic our tendency to believe things we ve been exposed to in the past the study presented subjects with headlines some false some true in a format identical to what users see on facebook rand found that simply being exposed to fake news like an article that claimed president trump was going to bring back the draft made people more likely to rate those stories as accurate later on in the experiment if you ve seen something before your brain subconsciously uses that as an indication that it s true rand says this is a tendency that propagandists have been aware of forever the difference is that it has never been easier to get eyeballs on the message nor to get enemies of the message to help spread it the researchers who conducted the pew poll noted that one reason people knowingly share made up news is to call out the stories as fake that might make a post popular among like minded peers on social media but it can also help false claims sink into the collective consciousness academics are only beginning to grasp all the ways our brains are shaped by the internet a key reason that stopping the spread of misinformation is so tricky one attempt by facebook shows how introducing new signals into this busy domain can backfire with hopes of curtailing junk news the company started attaching warnings to posts that contained claims that fact checkers had rated as false but a study found that this can make users more likely to believe any unflagged post tessa lyons laing a product manager who works on facebook s news feed says the company toyed with the idea of alerting users to hoaxes that were traveling around the web each day before realizing that an immunization approach might be counterproductive we re really trying to understand the problem and to be thoughtful about the research and therefore in some cases to move slower she says part of the issue is that people are still relying on outdated shortcuts the kind we were taught to use in a library take the professor in wineburg s study a list of citations means one thing when it appears in a book that has been vetted by a publisher a fact checker and a librarian it means quite another on the internet where everyone has access to a personal printing press newspapers used to physically separate hard news and commentary so our minds could easily grasp what was what but today two thirds of americans get news from social media where posts from publishers get the same packaging as birthday greetings and rants content that warrants an emotional response is mixed with things that require deeper consideration it all looks identical says harvard researcher claire wardle so our brain has to work harder to make sense of those different types of information instead of working harder we often try to outsource the job studies have shown that people assume that the higher something appears in google search results the more reliable it is but google s algorithms are surfacing content based on keywords not truth if you ask about using apricot seeds to cure cancer the tool will dutifully find pages asserting that they work a search engine is a search engine says richard gingras vice president of news at google i don t think anyone really wants google to be the arbiter of what is or is not acceptable expression that s just one example of how we need to retrain our brains we re also inclined to trust visuals says wardle but some photos are doctored and other legitimate ones are put in false contexts on twitter people use the size of others followings as a proxy for reliability yet millions of followers have been paid for and an estimated 10 of users may be bots in his studies wineburg found that people of all ages were inclined to evaluate sources based on features like the site s url and graphic design things that are easy to manipulate it makes sense that humans would glom on to just about anything when they re so worn out by the news but when we resist snap judgments we are harder to fool you just have to stop and think rand says of the experiments he has run on the subject all of the data we have collected suggests that s the real problem it s not that people are being super biased and using their reasoning ability to trick themselves into believing crazy stuff it s just that people aren t stopping they re rolling on that is of course the way social media platforms have been designed the endless feeds and intermittent rewards are engineered to keep you reading and there are other environmental factors at play like people s ability to easily seek out information that confirms their beliefs but rand is not the only academic who believes that we can take a big bite out of errors if we slow down wineburg an 18 year veteran of stanford works out of a small office in the center of the palm lined campus his group s specialty is developing curricula that teachers across the nation use to train kids in critical thinking now they re trying to update those lessons for life in a digital age with the help of funding from google which has devoted 3 million to the digital literacy project they are part of the researchers hope to deploy new rules of the road by next year outlining techniques that anyone can use to draw better conclusions on the web his group doesn t just come up with smart ideas it tests them but as they set out to develop these lessons they struggled to find research about best practices where are the studies about what superstars do so that we might learn from them wineburg recalls thinking sitting in the team s office beneath a print of the tabula rogeriana a medieval map that pictures the world in a way we now see as upside down eventually a cold email to an office in new york revealed a promising model professional fact checkers fact checkers they found didn t fall prey to the same missteps as other groups when presented with the american college of pediatricians task for example they almost immediately left the site and started opening new tabs to see what the wider web had to say about the organization wineburg has dubbed this lateral reading if a person never leaves a site as the professor failed to do they are essentially wearing blinders fact checkers not only zipped to additional sources but also laid their references side by side to better keep their bearings in another test the researchers asked subjects to assess the website minimumwage com in a few minutes time 100 of fact checkers figured out that the site is backed by a pr firm that also represents the restaurant industry a sector that generally opposes raising hourly pay only 60 of historians and 40 of stanford students made the same discovery often requiring a second prompt to find out who was behind the site another tactic fact checkers used that others didn t is what wineburg calls click restraint they would scan a whole page of search results maybe even two before choosing a path forward it s the ability to stand back and get a sense of the overall territory in which you ve landed he says rather than promiscuously clicking on the first thing this is important because people or organizations with an agenda can game search results by packing their sites with keywords so that those sites rise to the top and more objective assessments get buried the lessons they ve developed include such techniques and teach kids to always start with the same question who is behind the information although it is still experimenting a pilot that wineburg s team conducted at a college in california this past spring showed that such tiny behavioral changes can yield significant results another technique he champions is simpler still just read it one study found that 6 in 10 links get retweeted without users reading anything besides someone else s summation of it another found that false stories travel six times as fast as true ones on twitter apparently because lies do a better job of stimulating feelings of surprise and disgust but taking a beat can help us avoid knee jerk reactions so that we don t blindly add garbage to the vast flotillas already clogging up the web what makes the false or hyperpartisan claims do really well is they re a bit outlandish rand says that same thing that makes them successful in spreading online is the same thing that on reflection would make you realize it wasn t true tech companies have a big role to play in stemming the tide of misinformation and they re working on it but they have also realized that what harvard s wardle calls our information disorder cannot be solved by engineers alone algorithms are good at things like identifying fake accounts and platforms are flagging millions of them every week yet machines could only take facebook so far in identifying the most recent influence campaign one inauthentic page titled resisters ginned up a counterprotest to a white civil rights rally planned for august in washington d c and got legitimate organizations to help promote it more than 2 600 people expressed interest in going before facebook revealed that the page was part of a coordinated operation disabled the event and alerted users the company has hired thousands of content reviewers that have the sophistication to weed through tricky mixes of truth and lies but facebook can t employ enough humans to manually review the billions of posts that are put up each day across myriad countries and languages many misleading posts don t violate tech companies terms of service facebook one of the firms that removed content from jones said the decision did not relate to false news but prohibitions against rhetoric such as dehumanizing language apple and spotify cited rules against hate speech which is generally protected by the first amendment with free expression you get the good and the bad and you have to accept both says google s gingras and hopefully you have a society that can distinguish between the two you also need a society that cares about that distinction schools make sense as an answer but it will take money and political will to get new curricula into classrooms teachers must master new material and train students to be skeptical without making them cynical once you start getting kids to question information says stanford s sarah mcgrew they can fall into this attitude where nothing is reliable anymore advocates want to teach kids other defensive skills like how to reverse search an image to make sure a photo is really portraying what someone says it is and how to type a neutral query into the search bar but even if the perfect lessons are dispersed for free online anyone who has already graduated will need to opt in they will have to take initiative and also be willing to question their prejudices to second guess information they might like to believe and relying on open mindedness to defeat tribal tendencies has not proved a winning formula in past searches for truth that is why many advocates are suggesting that we reach for another powerful tool shame wardle says we need to make sharing misinformation as shameful as drunk driving wineburg invokes the environmental movement saying we need to cultivate an awareness of digital pollution on the internet we have to get people to think that they are littering wineburg says by forwarding stuff that isn t true the idea is to make people see the aggregate effect of little actions that one by one ill advised clicks contribute to the web s being a toxic place having a well informed citizenry may be in the big picture as important to survival as having clean air and water if we can t come together as a society around this issue wineburg says it is our doom this appears in the august 20 2018 issue of time write to katy steinmetz at katy steinmetz time com 